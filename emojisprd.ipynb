{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_emoji.csv',header=None)\n",
    "test = pd.read_csv('test_emoji.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dictionary = {\"0\": \"\\u2764\\uFE0F\",    # :heart: prints a black instead of red heart depending on the font\n",
    "                    \"1\": \":baseball:\",\n",
    "                    \"2\": \":beaming_face_with_smiling_eyes:\",\n",
    "                    \"3\": \":downcast_face_with_sweat:\",\n",
    "                    \"4\": \":fork_and_knife:\",\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(132,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "xtrain = train[0]\n",
    "\n",
    "xtest = test[0]\n",
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again ğŸ˜“\n",
      "I am proud of your achievements ğŸ˜\n",
      "It is the worst day in my life ğŸ˜“\n",
      "Miss you so much â¤ï¸\n",
      "food is life ğŸ´\n",
      "I love you mum â¤ï¸\n",
      "Stop saying bullshit ğŸ˜“\n",
      "congratulations on your acceptance ğŸ˜\n",
      "The assignment is too long  ğŸ˜“\n",
      "I want to go play âš¾\n"
     ]
    }
   ],
   "source": [
    "for ix in range(10):\n",
    "    print(xtrain[ix],emoji.emojize(emoji_dictionary[str(train[1][ix])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = to_categorical(train[1],num_classes=5)\n",
    "ytest = to_categorical(test[1],num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {}\n",
    "with open('glove.6B.50d.txt',encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coeffs = np.asarray(values[1:],dtype='float32')\n",
    "        \n",
    "        #print(word)\n",
    "        #print(coeffs)\n",
    "        embeddings[word] = coeffs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOutputEmbeddings(X):\n",
    "    \n",
    "    embedding_matrix_output = np.zeros((X.shape[0],10,50))\n",
    "    for ix in range(X.shape[0]):\n",
    "        X[ix] = X[ix].split()\n",
    "        for jx in range(len(X[ix])):\n",
    "            embedding_matrix_output[ix][jx] = embeddings[X[ix][jx].lower()]\n",
    "            \n",
    "    return embedding_matrix_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rahul\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "t = getOutputEmbeddings(xtrain)\n",
    "te = getOutputEmbeddings(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0804 15:59:07.130746  3496 deprecation_wrapper.py:119] From c:\\users\\rahul\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0804 15:59:07.181625  3496 deprecation_wrapper.py:119] From c:\\users\\rahul\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0804 15:59:07.184614  3496 deprecation_wrapper.py:119] From c:\\users\\rahul\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0804 15:59:08.003491  3496 deprecation_wrapper.py:119] From c:\\users\\rahul\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0804 15:59:08.025964  3496 deprecation.py:506] From c:\\users\\rahul\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0804 15:59:08.073838  3496 deprecation_wrapper.py:119] From c:\\users\\rahul\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0804 15:59:08.109867  3496 deprecation_wrapper.py:119] From c:\\users\\rahul\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 29,765\n",
      "Trainable params: 29,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64,input_shape = (10,50)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0804 15:59:08.998108  3496 deprecation.py:323] From c:\\users\\rahul\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 27 samples\n",
      "Epoch 1/20\n",
      "105/105 [==============================] - 4s 40ms/step - loss: 1.6045 - acc: 0.2381 - val_loss: 1.6013 - val_acc: 0.2963\n",
      "Epoch 2/20\n",
      "105/105 [==============================] - 0s 420us/step - loss: 1.5801 - acc: 0.2857 - val_loss: 1.5955 - val_acc: 0.2593\n",
      "Epoch 3/20\n",
      "105/105 [==============================] - 0s 323us/step - loss: 1.5494 - acc: 0.3905 - val_loss: 1.5926 - val_acc: 0.2593\n",
      "Epoch 4/20\n",
      "105/105 [==============================] - 0s 266us/step - loss: 1.5218 - acc: 0.4095 - val_loss: 1.5925 - val_acc: 0.2593\n",
      "Epoch 5/20\n",
      "105/105 [==============================] - 0s 237us/step - loss: 1.5041 - acc: 0.3714 - val_loss: 1.5954 - val_acc: 0.2222\n",
      "Epoch 6/20\n",
      "105/105 [==============================] - 0s 266us/step - loss: 1.4933 - acc: 0.4190 - val_loss: 1.5992 - val_acc: 0.2222\n",
      "Epoch 7/20\n",
      "105/105 [==============================] - 0s 218us/step - loss: 1.4618 - acc: 0.4381 - val_loss: 1.6045 - val_acc: 0.2222\n",
      "Epoch 8/20\n",
      "105/105 [==============================] - 0s 370us/step - loss: 1.4284 - acc: 0.4381 - val_loss: 1.6108 - val_acc: 0.2222\n",
      "Epoch 9/20\n",
      "105/105 [==============================] - 0s 209us/step - loss: 1.4146 - acc: 0.4571 - val_loss: 1.6170 - val_acc: 0.2222\n",
      "Epoch 10/20\n",
      "105/105 [==============================] - 0s 342us/step - loss: 1.4014 - acc: 0.4952 - val_loss: 1.6229 - val_acc: 0.2963\n",
      "Epoch 11/20\n",
      "105/105 [==============================] - 0s 237us/step - loss: 1.3558 - acc: 0.4762 - val_loss: 1.6227 - val_acc: 0.2593\n",
      "Epoch 12/20\n",
      "105/105 [==============================] - 0s 294us/step - loss: 1.3328 - acc: 0.4571 - val_loss: 1.6157 - val_acc: 0.2963\n",
      "Epoch 13/20\n",
      "105/105 [==============================] - 0s 247us/step - loss: 1.3008 - acc: 0.4857 - val_loss: 1.6013 - val_acc: 0.2222\n",
      "Epoch 14/20\n",
      "105/105 [==============================] - 0s 237us/step - loss: 1.2810 - acc: 0.4952 - val_loss: 1.5742 - val_acc: 0.2593\n",
      "Epoch 15/20\n",
      "105/105 [==============================] - 0s 218us/step - loss: 1.2185 - acc: 0.4667 - val_loss: 1.5288 - val_acc: 0.2593\n",
      "Epoch 16/20\n",
      "105/105 [==============================] - 0s 304us/step - loss: 1.1824 - acc: 0.4762 - val_loss: 1.4704 - val_acc: 0.2593\n",
      "Epoch 17/20\n",
      "105/105 [==============================] - 0s 408us/step - loss: 1.1417 - acc: 0.5333 - val_loss: 1.4000 - val_acc: 0.2593\n",
      "Epoch 18/20\n",
      "105/105 [==============================] - 0s 275us/step - loss: 1.1032 - acc: 0.5429 - val_loss: 1.3231 - val_acc: 0.3704\n",
      "Epoch 19/20\n",
      "105/105 [==============================] - 0s 209us/step - loss: 1.0474 - acc: 0.5714 - val_loss: 1.2700 - val_acc: 0.3704\n",
      "Epoch 20/20\n",
      "105/105 [==============================] - 0s 294us/step - loss: 1.0171 - acc: 0.5714 - val_loss: 1.2360 - val_acc: 0.4074\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(\"bestmodel.h5\",monitor = \"val_loss\",verbose = True,save_best_only = True)\n",
    "earlystop = EarlyStopping(monitor = 'val_acc',patience = 10)\n",
    "hist = model.fit(t,ytrain,epochs = 20,shuffle=True,validation_split=0.2,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 3, 4, 3, 3,\n",
       "       2, 2, 3, 3, 2, 2, 3, 2, 2, 1, 2, 2, 3, 2, 2, 2, 2, 2, 3, 2, 2, 1,\n",
       "       2, 2, 3, 2, 3, 3, 3, 2, 3, 2, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_  = model.predict_classes(te)\n",
    "y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'want', 'to', 'eat']\n",
      "ğŸ´\n",
      "ğŸ˜“\n",
      "['he', 'did', 'not', 'answer']\n",
      "ğŸ˜“\n",
      "ğŸ˜“\n",
      "['he', 'got', 'a', 'raise']\n",
      "ğŸ˜\n",
      "ğŸ˜“\n",
      "['she', 'got', 'me', 'a', 'present']\n",
      "â¤ï¸\n",
      "ğŸ˜\n",
      "['ha', 'ha', 'ha', 'it', 'was', 'so', 'funny']\n",
      "ğŸ˜\n",
      "ğŸ˜\n",
      "['he', 'is', 'a', 'good', 'friend']\n",
      "â¤ï¸\n",
      "ğŸ˜\n",
      "['I', 'am', 'upset']\n",
      "â¤ï¸\n",
      "ğŸ˜“\n",
      "['We', 'had', 'such', 'a', 'lovely', 'dinner', 'tonight']\n",
      "â¤ï¸\n",
      "ğŸ˜\n",
      "['where', 'is', 'the', 'food']\n",
      "ğŸ´\n",
      "ğŸ˜\n",
      "['Stop', 'making', 'this', 'joke', 'ha', 'ha', 'ha']\n",
      "ğŸ˜\n",
      "ğŸ˜\n",
      "['where', 'is', 'the', 'ball']\n",
      "âš¾\n",
      "ğŸ˜\n",
      "['work', 'is', 'hard']\n",
      "ğŸ˜“\n",
      "ğŸ˜\n",
      "['This', 'girl', 'is', 'messing', 'with', 'me']\n",
      "ğŸ˜“\n",
      "ğŸ˜\n",
      "['are', 'you', 'serious', 'ha', 'ha']\n",
      "ğŸ˜\n",
      "ğŸ˜\n",
      "['Let', 'us', 'go', 'play', 'baseball']\n",
      "âš¾\n",
      "âš¾\n",
      "['This', 'stupid', 'grader', 'is', 'not', 'working']\n",
      "ğŸ˜“\n",
      "ğŸ˜\n",
      "['work', 'is', 'horrible']\n",
      "ğŸ˜“\n",
      "ğŸ˜\n",
      "['Congratulation', 'for', 'having', 'a', 'baby']\n",
      "ğŸ˜\n",
      "ğŸ˜\n",
      "['stop', 'messing', 'around']\n",
      "ğŸ˜“\n",
      "ğŸ˜“\n",
      "['any', 'suggestions', 'for', 'dinner']\n",
      "ğŸ´\n",
      "ğŸ´\n",
      "['I', 'love', 'taking', 'breaks']\n",
      "â¤ï¸\n",
      "ğŸ˜“\n",
      "['you', 'brighten', 'my', 'day']\n",
      "ğŸ˜\n",
      "ğŸ˜“\n",
      "['I', 'boiled', 'rice']\n",
      "ğŸ´\n",
      "ğŸ˜\n",
      "['she', 'is', 'a', 'bully']\n",
      "ğŸ˜“\n",
      "ğŸ˜\n",
      "['Why', 'are', 'you', 'feeling', 'bad']\n",
      "ğŸ˜“\n",
      "ğŸ˜“\n",
      "['I', 'am', 'upset']\n",
      "ğŸ˜“\n",
      "ğŸ˜“\n",
      "['I', 'worked', 'during', 'my', 'birthday']\n",
      "ğŸ˜“\n",
      "ğŸ˜\n",
      "['My', 'grandmother', 'is', 'the', 'love', 'of', 'my', 'life']\n",
      "â¤ï¸\n",
      "ğŸ˜\n",
      "['enjoy', 'your', 'break']\n",
      "ğŸ˜\n",
      "ğŸ˜“\n",
      "['valentine', 'day', 'is', 'near']\n",
      "â¤ï¸\n",
      "ğŸ˜\n"
     ]
    }
   ],
   "source": [
    "for ix in range(30):\n",
    "    print(xtest[ix])\n",
    "    print(emoji.emojize(emoji_dictionary[str(np.argmax(ytest[ix]))]))\n",
    "    print(emoji.emojize(emoji_dictionary[str(y_[ix])]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 199us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3838989394051688, 0.5714285629136222]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.evaluate(te,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
